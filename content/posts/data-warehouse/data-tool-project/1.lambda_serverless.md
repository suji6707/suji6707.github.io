+++
title = 'Lambda'
date = 2024-08-21T00:20:22+09:00
draft = true
+++

### 파이썬 실행

---
#### OS 문제
Turned out to be an architecture compatibility issue -

Needed to make sure the arch matched between the lambda function, and the docker image.

Locally I was building on an M1 with arm64 but the function is configured by default to use amd64

I changed my build command to
docker buildx build --platform linux/amd64 -t <image_name>:<image_tag>

Although I could have also updated the arch type for the lambda function to use arm64

💎 이 경우, yml에서
빌드 이미지 OS랑 
serverelss가 람다 실행할때 OS랑 둘다 arm으로 맞춰주면 됨.
```yml
provider:
  ecr:
    images:
      helloimage:
        path: .
        platform: linux/arm64

  name: aws
  runtime: python3.11
  architecture: arm64
```
---
#### Docker requirements
도커파일로 파이썬 requirements 설치하는게 베스트.
InvalidEntrypoint 에러가 떴었는데, aws 컨테이너에서 도커파일 사용시 권장되는
`ENV LAMBDA_TASK_ROOT=/var/task`가 빠져있기 때문이었을듯.
`COPY handler.py ${LAMBDA_TASK_ROOT}/`
이미 aws에서 배포시 pwd가 /var/task로 설정되어있고,
실제 실행할 파일이 해당 폴더안으로 들어감.

최종적으로 아래와 같은데, 포인트는
- requirements 파일을 복사 후 install을 해줘야한다는 것
   - 어차피 . 가 /var/task라서 여기서 바로하면 됨
- 파이썬 환경에서 duckdb import 후 httpfs 익스텐션 설치.

```shell
# Base image
FROM public.ecr.aws/lambda/python:3.9

# Set environment variables
ENV HOME=/home/aws
ENV LAMBDA_TASK_ROOT=/var/task

# Install pip and other dependencies
RUN pip3 install --upgrade pip \
	&& yum install gcc gcc-c++ -y

COPY requirements.txt .

RUN pip3 install -r requirements.txt

# Create a directory for additional files
RUN mkdir -p ${HOME}

# Run a Python command to set up duckdb
RUN python3 -c "import duckdb; duckdb.query('INSTALL httpfs;');"

# Copy the application code to the container
COPY handler.py ${LAMBDA_TASK_ROOT}/

# Set the CMD to the lambda handler
CMD [ "handler.hello" ]
```
---
#### requirements 플러그인 (필요없음)
python requirements 플러그인의 역할
- dockerizePip: true
   - pip로 패키지를 설치할 때 반드시 도커를 쓰라는 명령어. 
- false: 도커 패키지 사용하지 않지만, 의존성 네이티브 패키지를 빌드할거면 반드시 필요할 것.


```
.project_root/
│
├── .requirements/
│   ├── requests/
│   ├── numpy/
│   └── ... (기타 종속성 파일들)
│
├── requests -> .requirements/requests (심볼릭 링크)
├── numpy -> .requirements/numpy (심볼릭 링크)
│
├── handler.py
└── serverless.yml
```
Serverless 프레임워크는 이 상태에서 프로젝트를 패키징하고 AWS Lambda에 배포합니다. 배포가 완료되면, 플러그인은 생성된 심볼릭 링크를 정리하여 디렉토리를 청결하게 유지합니다.

```
.project_root/
│
├── .requirements/
│   ├── requests/
│   ├── numpy/
│   └── ... (기타 종속성 파일들)
│
├── handler.py
└── serverless.yml
```
심볼릭 링크가 제거된 후, .requirements/ 디렉토리만 남고 최상위 디렉토리는 청결하게 유지됩니다.slsss

---

이 문제는 AWS Lambda 함수의 패키지 유형(PackageType)을 변경하려고 할 때 발생하는 오류입니다. AWS Lambda 함수는 두 가지 패키지 유형을 지원합니다: Zip과 Image.
이 오류 메시지는 기존에 Zip 유형으로 배포된 Lambda 함수를 Image 유형으로 업데이트하려고 할 때 발생합니다. 
AWS CloudFormation 또는 Serverless Framework에서는 이러한 유형 변경을 직접 지원하지 않습니다.

----
#### Makefile vs Dockerfile

Makefile은 일반적으로 C/C++와 같은 컴파일 언어에서 빌드 자동화를 위해 사용되지만, 파이썬 프로젝트에서도 빌드, 테스트, 배포 등의 작업을 자동화하는 데 유용하게 사용할 수 있습니다. Makefile은 `make` 명령어와 함께 사용되며, 특정 작업을 자동으로 실행하는 규칙과 명령어를 정의합니다.

파이썬 프로젝트에서 Makefile을 사용하는 방법은 다음과 같습니다:

1. **Makefile 작성**: 프로젝트 루트 디렉토리에 `Makefile`이라는 파일을 생성하고, 그 안에 필요한 작업을 정의합니다. 각 작업은 "타겟"이라는 이름으로 정의되며, 해당 타겟이 실행될 때 수행할 명령어를 지정합니다.

    ```Makefile
    # Makefile 예시
    .PHONY: install test lint clean

    install:
        pip install -r requirements.txt

    test:
        pytest tests/

    lint:
        pylint mymodule/

    clean:
        find . -type f -name "*.pyc" -delete
        find . -type d -name "__pycache__" -delete
    ```

    위의 예시에서 `install`, `test`, `lint`, `clean`이라는 타겟이 정의되어 있습니다.

2. **Make 명령어 실행**: 터미널에서 `make <타겟>` 명령어를 실행하여 해당 타겟에 정의된 작업을 수행합니다.

    ```sh
    # 패키지 설치
    make install

    # 테스트 실행
    make test

    # 코드 린트 검사
    make lint

    # 불필요한 파일 삭제
    make clean
    ```

Makefile의 각 타겟은 자동으로 실행되지 않으며, 명시적으로 `make <타겟>` 명령어를 실행해야 합니다. 예를 들어, `make test`를 실행하면 `Makefile`의 `test` 타겟에 정의된 `pytest tests/` 명령어가 실행됩니다.

Makefile을 사용하면 파이썬 프로젝트에서 반복적인 작업을 쉽게 자동화할 수 있으며, 팀원 간의 일관성을 유지하는 데 도움이 됩니다.

---

#### params 넘기기

`serverless invoke local` 명령어를 사용하여 JSON 파일을 통해 데이터를 전달하는 방법과, API 호출마다 다른 데이터를 전달하는 방법에 대해 설명드리겠습니다.

### JSON 파일을 통해 데이터 전달

1. **JSON 파일 생성**:
   예를 들어, `event1.json` 파일을 생성합니다.
   ```json
   {
     "queryStringParameters": {
       "name": "Alice"
     }
   }
   ```

2. **JSON 파일을 사용하여 함수 호출**:
   ```sh
   sls invoke local -f hello -p event1.json
   ```

이 방법을 사용하면 JSON 파일에 정의된 데이터가 Lambda 함수에 전달됩니다.

### API 호출마다 다른 데이터를 전달

API 호출마다 다른 데이터를 전달해야 하는 경우, 여러 JSON 파일을 생성하거나, `--data` 옵션을 사용하여 명령어에서 직접 데이터를 전달할 수 있습니다.

#### 여러 JSON 파일 사용

1. **여러 JSON 파일 생성**:
   예를 들어, `event1.json`, `event2.json` 파일을 생성합니다.

   `event1.json`:
   ```json
   {
     "queryStringParameters": {
       "name": "Alice"
     }
   }
   ```

   `event2.json`:
   ```json
   {
     "queryStringParameters": {
       "name": "Bob"
     }
   }
   ```

2. **JSON 파일을 사용하여 각각의 함수 호출**:
   ```sh
   sls invoke local -f hello -p event1.json
   sls invoke local -f hello -p event2.json
   ```

#### `--data` 옵션 사용

명령어에서 직접 데이터를 전달하려면 `--data` 옵션을 사용할 수 있습니다.

1. **명령어에서 직접 데이터 전달**:
   ```sh
   sls invoke local -f hello -d '{"queryStringParameters": {"name": "Alice"}}'
   sls invoke local -f hello -d '{"queryStringParameters": {"name": "Bob"}}'
   ```

이 방법을 사용하면 JSON 파일을 생성하지 않고도 명령어에서 직접 데이터를 전달할 수 있습니다.

### 자동화 스크립트 사용

API 호출마다 다른 데이터를 전달하는 작업을 자동화하고 싶다면, 스크립트를 작성하여 여러 호출을 자동으로 수행할 수 있습니다. 예를 들어, Bash 스크립트를 작성할 수 있습니다.

1. **Bash 스크립트 작성** (`invoke.sh`):
   ```sh
   #!/bin/bash

   # Define an array of JSON data
   events=(
     '{"queryStringParameters": {"name": "Alice"}}'
     '{"queryStringParameters": {"name": "Bob"}}'
     '{"queryStringParameters": {"name": "Charlie"}}'
   )

   # Loop through the array and invoke the function with each set of data
   for event in "${events[@]}"
   do
     echo "Invoking with event: $event"
     sls invoke local -f hello -d "$event"
   done
   ```

2. **스크립트 실행 권한 부여 및 실행**:
   ```sh
   chmod +x invoke.sh
   ./invoke.sh
   ```

이 스크립트는 정의된 JSON 데이터를 사용하여 `sls invoke local` 명령어를 여러 번 실행합니다.

### 결론

- **JSON 파일**을 사용하여 데이터를 전달하는 경우, 파일을 여러 개 생성하여 각각의 데이터를 전달할 수 있습니다.
- **`--data` 옵션**을 사용하여 명령어에서 직접 데이터를 전달할 수 있습니다.
- **자동화 스크립트**를 작성하여 여러 호출을 자동으로 수행할 수 있습니다.

이 방법들을 통해 API 호출마다 다른 데이터를 효율적으로 전달할 수 있습니다.

---
#### S3 버킷 액세스시

Serverless Framework를 사용하여 S3 버킷을 정의하고 배포할 때, `sls remove` 명령어를 사용하면 기본적으로 S3 버킷도 삭제됩니다. 이는 Serverless Framework가 배포된 모든 리소스를 제거하는 동작을 하기 때문입니다.

그러나 중요한 데이터를 갖고 있는 S3 버킷이 삭제되지 않도록 하기 위해서는 다음과 같은 방법을 사용할 수 있습니다:

1. **Serverless Framework의 `retain` 옵션 사용**:
   CloudFormation 템플릿에서 `DeletionPolicy`를 `Retain`으로 설정하여 S3 버킷이 삭제되지 않도록 할 수 있습니다.

2. **수동으로 S3 버킷을 생성**:
   Serverless Framework를 사용하지 않고, 미리 수동으로 S3 버킷을 생성하고, Serverless Framework에서 이를 참조만 하도록 설정할 수 있습니다.

### 1. `retain` 옵션 사용

Serverless Framework는 CloudFormation을 사용하여 리소스를 관리합니다. 이를 통해 `DeletionPolicy`를 설정할 수 있습니다. `serverless.yml` 파일을 다음과 같이 수정합니다:

```yaml
service: my-service

provider:
  name: aws
  runtime: python3.8

resources:
  Resources:
    MyS3Bucket:
      Type: AWS::S3::Bucket
      Properties:
        BucketName: my-unique-bucket-name
      DeletionPolicy: Retain

functions:
  myFunction:
    handler: handler.lambda_handler
    events:
      - s3:
          bucket: my-unique-bucket-name
          event: s3:ObjectCreated:*

```

`DeletionPolicy: Retain`을 추가하면 `sls remove` 명령어를 실행하더라도 S3 버킷은 삭제되지 않습니다.

### 2. 수동으로 S3 버킷을 생성하고 참조

미리 S3 버킷을 수동으로 생성하고, `serverless.yml` 파일에서 이 버킷을 참조하도록 설정할 수 있습니다:

```yaml
service: my-service

provider:
  name: aws
  runtime: python3.8

functions:
  myFunction:
    handler: handler.lambda_handler
    events:
      - s3:
          bucket: my-existing-bucket-name
          event: s3:ObjectCreated:*
```

이 경우, `sls remove` 명령어를 실행하더라도 Serverless Framework는 해당 버킷을 삭제하려고 하지 않습니다.

이 두 가지 방법을 통해 중요한 데이터를 갖고 있는 S3 버킷이 실수로 삭제되지 않도록 할 수 있습니다. 이 외에도, Serverless Framework의 기능과 CloudFormation의 다양한 설정을 활용하여 적절하게 리소스를 관리할 수 있습니다.

---
### IAM role 정의

serverless.yml 파일에서 IAM 역할을 정의하는 것은 Serverless Framework가 배포하는 Lambda 함수들이 특정 권한을 가지도록 하기 위해 사용됩니다. 이 역할은 Lambda 함수가 실행될 때 사용되는 권한을 정의합니다

즉,
배포할 때 계정에서 필요한 권한
aws root 계정 -> 전부 열려있어서 된것.

한편 yml 안에서 정의된 iam은 새로 iam을 발급
- iam 생성권한, s3, cloudformation, lambda 등 권한 필수.
사용자는 람다함수.

--
Serverless Framework가 AWS에 접근하기 위해 필요한 권한은 수행하려는 작업에 따라 다릅니다. 하지만 일반적으로 Serverless Framework는 AWS 리소스를 생성하고 관리하기 위해 IAM 사용자 또는 역할을 통해 권한을 위임받아야 합니다. 

다음은 Serverless Framework가 일반적으로 요구하는 권한과 그 이유입니다.

**1. CloudFormation 권한:**

* Serverless Framework는 CloudFormation을 사용하여 Lambda 함수, API Gateway, DynamoDB 테이블과 같은 AWS 리소스를 배포하고 관리합니다. 따라서 Serverless Framework를 사용하는 IAM 사용자 또는 역할은 다음과 같은 CloudFormation 작업을 수행할 수 있는 권한이 필요합니다.
    * `cloudformation:CreateStack`
    * `cloudformation:DescribeStacks`
    * `cloudformation:UpdateStack`
    * `cloudformation:DeleteStack`
    * `cloudformation:DescribeStackEvents`
    * `cloudformation:GetTemplate`

**2. 서비스별 권한:**

* Serverless Framework는 Lambda 함수, API Gateway, DynamoDB 테이블 등 다양한 AWS 서비스를 사용하여 애플리케이션을 배포합니다. 따라서 사용하는 서비스에 따라 해당 서비스에 대한 특정 권한이 필요합니다. 예를 들어, Lambda 함수를 생성하고 관리하려면 다음과 같은 권한이 필요할 수 있습니다.
    * `lambda:CreateFunction`
    * `lambda:GetFunction`
    * `lambda:UpdateFunctionConfiguration`
    * `lambda:UpdateFunctionCode`
    * `lambda:DeleteFunction`
    * `lambda:InvokeFunction`
    * `iam:CreateRole` 
    * `iam:PutRolePolicy`
    * `iam:PassRole`

**3. S3 버킷 접근 권한:**

* Serverless Framework는 배포 패키지를 저장하고 CloudFormation 템플릿을 업로드하기 위해 S3 버킷을 사용합니다. 따라서 Serverless Framework를 사용하는 IAM 사용자 또는 역할은 다음과 같은 S3 작업을 수행할 수 있는 권한이 필요합니다.
    * `s3:CreateBucket` 
    * `s3:PutObject`
    * `s3:GetObject`
    * `s3:DeleteObject`
    * `s3:ListBucket`

**최소 권한:**

* 보안을 위해 Serverless Framework에 필요한 최소한의 권한만 부여하는 것이 좋습니다. Serverless Framework가 실제로 사용하는 권한은 `serverless.yml` 파일에 정의된 설정과 사용하는 플러그인에 따라 달라질 수 있습니다. 

**권한 부여 방법:**

* Serverless Framework에 필요한 권한은 IAM 정책을 통해 부여할 수 있습니다. IAM 정책을 생성하고 Serverless Framework를 사용하는 IAM 사용자 또는 역할에 연결할 수 있습니다. AWS 콘솔, AWS CLI 또는 SDK를 사용하여 IAM 정책을 관리할 수 있습니다.

**주의 사항:**

* 위에 나열된 권한은 일반적인 예시이며 실제 필요한 권한은 프로젝트에 따라 다를 수 있습니다.
* Serverless Framework 공식 문서 및 사용하는 플러그인의 문서를 참조하여 필요한 권한을 확인하는 것이 좋습니다.

Serverless Framework를 사용하여 AWS 리소스를 안전하게 관리하려면 필요한 최소한의 권한을 부여하고 정기적으로 IAM 정책을 검토하여 불필요한 권한을 제거하는 것이 중요합니다.


---
### 로그
AWS Lambda 함수의 로그를 보는 방법은 다음과 같습니다:

1. AWS CloudWatch 콘솔 사용:

   - AWS 콘솔에 로그인하고 CloudWatch 서비스로 이동합니다.
   - 왼쪽 메뉴에서 "로그 그룹"을 선택합니다.
   - "/aws/lambda/[함수이름]" 형식의 로그 그룹을 찾아 클릭합니다.
   - 로그 스트림 목록에서 최신 스트림을 선택하여 로그를 확인합니다.

2. AWS CLI 사용:

   ```
   aws logs get-log-events --log-group-name "/aws/lambda/[함수이름]" --log-stream-name "[로그스트림이름]"
   ```

3. Lambda 콘솔에서 직접 확인:

   - Lambda 콘솔에서 해당 함수를 선택합니다.
   - "모니터링" 탭으로 이동합니다.
   - "로그" 섹션에서 최근 로그를 확인할 수 있습니다.

4. 코드에서 로깅:

   - `console.log()` 등의 메서드를 사용하여 코드 내에서 로그를 생성합니다.
   - 이 로그들은 자동으로 CloudWatch에 전송됩니다.

5. 구조화된 로깅 사용:

   - JSON 형식의 구조화된 로그를 사용하면 분석이 더 쉬워집니다.
   - Lambda 콘솔의 "구성" 탭에서 JSON 로그 형식을 활성화할 수 있습니다.

6. 외부 로깅 도구 사용:

   - Better Stack 같은 외부 로깅 서비스를 사용하여 더 강력한 분석과 알림 기능을 활용할 수 있습니다.

로그를 효과적으로 활용하려면 적절한 로그 레벨 설정, 구조화된 로깅 사용, 그리고 필요한 경우 외부 도구를 통한 고급 분석을 고려해보세요.

---
### 서버리스에서 .env 문제
#### 💎 두 가지 방법
1. `useDotenv: true` 
- yml내 environment에 .env 키값들을 정의해주고
코드에서 os.getenv(노드에선 process.env)로 쓸 수 있음
🌠 load_dotenv()를 쓰지 않음!! yml에서 이미 주입한거라
2. `serverless-dotenv-plugin` 
- `sls plugin install -n serverless-dotenv-plugin` 로 설치
- yml에 설정
```
plugins:
  - serverless-dotenv-plugin
```

🔺 결론적으로 sls deploy를 할 때 플러그인이 반영되고 
람다함수를 invoke할 때마다 그 플러그인이 작동하는듯.
중간에 yml을 바꾼건 영향을 주지않음.

🔺 액세스키로 권한을 줄거면 yml의 IAM을 정의하지 않아도 되는듯. 이중으로 ㄴㄴ.
- serverless deploy는 첨에 aws config로 키를 입력한 IAM role(루트계정의 Admin 등)로 실행되는거고
- serverless invoke는 yml 또는 .env에 정의된 액세스키 기반으로 권한을 갖고 AWS리소스에 접근하는 것임.

#### 원인?
Serverless Framework와 `.env` 파일, 그리고 `dotenv` 패키지 사용에 관한 이 상황은 몇 가지 중요한 이유와 설계 결정에 기인합니다:

1. 실행 컨텍스트의 차이:
   - Serverless Framework는 로컬에서 실행되는 도구입니다.
   - Lambda 함수는 AWS 클라우드 환경에서 실행됩니다.
   이 두 환경은 서로 다른 실행 컨텍스트를 가지고 있어, 로컬의 `.env` 파일이 자동으로 클라우드 환경에 전달되지 않습니다.

2. 보안 고려사항:
   - `.env` 파일은 종종 민감한 정보를 포함합니다.
   - 이러한 정보가 자동으로 클라우드에 업로드되는 것은 보안상 위험할 수 있습니다.

3. 클라우드 네이티브 접근:
   - AWS Lambda와 같은 서비스는 자체적인 환경 변수 관리 메커니즘을 제공합니다.
   - Serverless Framework는 이러한 클라우드 네이티브 접근 방식을 따르도록 설계되었습니다.

4. 명시적 구성 선호:
   - 어떤 환경 변수가 함수에 전달되는지 명확하게 하기 위해, 설정 파일에서 이를 명시적으로 정의하도록 유도합니다.

5. `dotenv` 패키지의 역할:
   - `dotenv`는 주로 개발 환경에서 사용됩니다.
   - 프로덕션 환경(AWS Lambda)에서는 다른 방식으로 환경 변수를 관리하는 것이 일반적입니다.

6. 다양한 배포 시나리오:
   - 개발, 스테이징, 프로덕션 등 다양한 환경에 대해 서로 다른 환경 변수 세트가 필요할 수 있습니다.
   - 단일 `.env` 파일에 의존하는 것은 이러한 다양한 시나리오를 관리하기 어렵게 만들 수 있습니다.

해결 방법:

1. Serverless Framework 설정:
   ```yaml
   useDotenv: true
   
   provider:
     environment:
       VAR1: ${env:VAR1}
       VAR2: ${env:VAR2}
   ```

2. 함수 코드에서 `dotenv` 사용:
   ```javascript
   if (process.env.NODE_ENV !== 'production') {
     require('dotenv').config();
   }
   ```

3. `serverless-dotenv-plugin` 사용:
   이 플러그인을 사용하면 `.env` 파일의 모든 변수를 자동으로 Lambda 함수에 주입할 수 있습니다.

이러한 접근 방식은 개발의 용이성과 프로덕션 환경의 보안 및 유연성 사이의 균형을 맞추려는 노력의 결과입니다. 개발자가 환경 변수를 명시적으로 관리하도록 유도하면서도, 필요한 경우 유연성을 제공합니다.

---
### 로깅

이 내용은 AWS Lambda에서 Python 런타임을 사용할 때 로깅이 제대로 작동하지 않는 이유와 이를 해결하는 방법에 대해 설명하고 있습니다. 

### 요약

1. **문제 설명:**
   - AWS Lambda의 Python 런타임은 기본적으로 로깅 핸들러를 사전 구성합니다.
   - 선택한 런타임 버전에 따라 로그 메시지의 형식을 수정하거나 메타데이터를 추가할 수 있습니다.
   - 하지만 **로그 레벨(log-level)**은 사전 구성되지 않습니다.
   - 따라서, 로그 메시지를 보내더라도 실제로 출력되지 않습니다.

2. **해결 방법:**
   - AWS Lambda 컨텍스트에서 로깅 라이브러리를 올바르게 사용하려면 루트 로거(root-logger)의 로그 레벨을 설정해야 합니다.

### 코드 설명

**기본적인 설정:**

```python
import logging
logging.getLogger().setLevel(logging.INFO)
```

위 코드는 루트 로거의 로그 레벨을 `INFO`로 설정합니다. 이 설정을 통해 로그 메시지가 올바르게 출력되도록 합니다.

**로컬 환경에서도 작동하도록 설정:**

로컬 Python 인터프리터에서도 동일한 스크립트를 실행할 수 있도록 하기 위해, 핸들러가 설정되어 있는지 확인하고, 설정되어 있지 않다면 기본 설정을 적용합니다.

```python
if len(logging.getLogger().handlers) > 0:
    # Lambda 환경에서는 stderr로 로깅하는 핸들러가 사전 구성되어 있습니다.
    # 만약 핸들러가 이미 설정되어 있다면, `.basicConfig`는 실행되지 않습니다.
    # 따라서, 로그 레벨을 직접 설정합니다.
    logging.getLogger().setLevel(logging.INFO)
else:
    # 핸들러가 설정되어 있지 않다면, 기본 설정을 적용합니다.
    logging.basicConfig(level=logging.INFO)
```

이 코드의 의미는 다음과 같습니다:

1. **핸들러가 이미 설정된 경우:**
   - AWS Lambda 환경에서는 기본적으로 stderr로 로깅하는 핸들러가 사전 구성되어 있습니다.
   - 이 경우, `basicConfig`는 실행되지 않으므로, 로그 레벨을 직접 설정합니다.

2. **핸들러가 설정되지 않은 경우:**
   - 로컬 환경에서는 핸들러가 설정되지 않을 수 있습니다.
   - 이 경우, `basicConfig`를 사용하여 기본 stderr 핸들러를 생성하고 로그 레벨을 설정합니다.

### 결론

이 설정을 통해 Python 스크립트가 AWS Lambda 환경과 로컬 환경 모두에서 올바르게 로그 메시지를 출력할 수 있도록 합니다. 

예를 들어, Lambda 함수 내에서 로그를 남기고 싶다면 다음과 같이 할 수 있습니다:

```python
import logging

if len(logging.getLogger().handlers) > 0:
    logging.getLogger().setLevel(logging.INFO)
else:
    logging.basicConfig(level=logging.INFO)

def lambda_handler(event, context):
    logging.info("This is an info message")
    logging.error("This is an error message")
    return "Hello, World!"
```

이렇게 하면 로그 메시지가 AWS Lambda 환경에서도, 로컬 환경에서도 올바르게 출력됩니다. 😊

---

로그 핸들러란?
- 로그 메시지를 어디에 어떤 방식으로 출력할지 결정하는 역할을 합니다.
•StreamHandler: 로그 메시지를 stdout (표준 출력) 또는 stderr (표준 에러)로 전송합니다.•FileHandler: 지정된 파일에 로그 메시지를 기록합니다.

logging 라이브러리: 로그레벨 설정, 형식 지정 등 다양한 기능.
`logging.basicConfig(level=logging.INFO)`
- 로깅모듈 기본설정. 

```python
if len(logging.getLogger().handlers) > 0:
    # The Lambda environment pre-configures a handler logging to stderr. If a handler is already configured,
    # `.basicConfig` does not execute. Thus we set the level directly.
    logging.getLogger().setLevel(logging.INFO)
else:
    logging.basicConfig(level=logging.INFO)
```
- 람다 환경은 로깅 핸들러를 기본적으로 stderr로 설정. (getLogger()의 대상이 stder)
이미 설정된 경우 level을 다이렉트로 설정
- 그렇지 않은경우 logging 라이브러리단에서 레벨 설정. 