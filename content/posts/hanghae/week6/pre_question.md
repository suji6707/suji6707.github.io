+++
title = 'week6 Q&A'
date = 2025-07-07T00:20:22+09:00
draft = true
+++

🔵WEEK6 코치님 사전질문 답변!

🍎1. 콘서트 예약 시스템에서 캐싱을 사용하면 효과적인 유스케이스가 무엇이 있을까요?
우선 조회, 새로고침이 가장 잦은건 예약페이지에서 좌석정보를 조회하는 것일 것 같습니다. 
concert schedule id (KEY)에 대한 50개 좌석정보(VALUE)를 캐싱
그런데 누군가 예약을 해서 좌석 정보가 변경되면 동시에 해당 schedule id에 대한 캐시를 비워주게되면 다음번 조회시 캐시미스가 발생할테고, 
예약변경이 잦게 일어난다면 캐시미스가 꽤 많을것 같습니다..
그럼에도 필요할지, 아니면 다른 더 효과적인 유스케이스가 있을지 궁금합니다
+
생각해보면 인메모리는 micro second, DB 쿼리는 milli second 단위인것 감안하면 
무조건 캐싱을 하는게 맞긴 한것같은데
실무에서는 이처럼 업데이트가 잦게 일어나는 정보를 캐싱할 때 효율을 높이기 위한 방법이 있을지 궁금합니다. 

---
캐싱을 사용하면 효과적인 케이스는 ‘웬만해서 잘 변하지 않는 데이터’라는 점을 상기시키면서 잘 생각하다 보면, 어떤 데이터가 있을 때 ‘변하는 부분’과 ‘변하지 않는 부분’으로 나누어볼 수 있다는 사실을 깨닫게 됩니다.
예를 들어 공연의 좌석 정보를 불러올 때를 가정하면, 자주 바뀌는 부분은 좌석별 선점 정보이며, 좌석 자체에 대한 정보(좌석의 고유 코드, 몇번째 라인에 몇번째 자리인지, 좌석 등급, 좌석의 가격 등)는 웬만해서는 안바뀌는 정보들이겠죠.

그렇다면 일단 이런 좌석 정보를 따로 분리하고 여기에 캐싱을 적용하는게 1차적으로 시도해볼 수 있는 방법일겁니다.
2차적으로는 좌석 선점 유무에도 캐싱을 적용하면 안되는 이유는 특별히 없습니다. 다만 말씀주신것처럼 좌석 선점 정보가 바뀔때마다 단순히 캐시 키를 삭제(invalidtion)을 해버리면 상당히 많이 캐시 미스가 일어날 것이기 때문에, 단순히 삭제 시키는 것 보다 그냥 좌석 선점 정보가 변경되면 DB를 업데이트해줌과 동시에 Redis 안에 있는 value도 업데이트 해주는 식으로 하면 캐시미스를 방어할 수 있습니다. 
(🔺삭제 시키는 것과 무슨 차이인지 헷갈리실 수 있는데, 캐시미스 상태에서 동시에 여러명이 같은 요청을 날린다면 그 요청이 전부 DB로 빠지는 상황을 생각해볼 수 있습니다. 물론 단순히 삭제 시키고 분산락으로 방어하는 방법도 있습니다!) 

---
🍎2. 메모리 캐시와 외부 캐시를 어떤식으로 나눠서 쓰면 좋을까요?
좌석상태는 어떤 서버에 접속하든 항상 동일해야하므로 외부 캐시에 있어야할 것 같은데,
콘서트 목록같은건 잘 변경되지 않아서 애플리케이션 내부 캐시에 있어도 될거같습니다. 
이 경우 아래처럼 caching IP를 다르게 설정하여 비즈니스 로직에서 구분하여 사용하면 될까요?
(항상 단일 외부 캐시 서버만 사용해왔다보니 이렇게 구분해서 쓰는것이 어렵게 느껴지네요.. ;;)

---
우선 지수님께서 말씀 주신대로, 잘 변하지 않고 자주 읽어야하는 데이터는 인메모리에 있어야 유리하고 어떤 인스턴스에서 읽어도 같은 값을 반환하기 위해서는 외부 캐시를 사용해야합니다.
따라서 이렇게 용도에 맞게 일부 데이터를 인메모리 캐시에 담아두게 되면 Redis에 가해지는 부하를 줄일 수 있습니다.

다만 생각해야할게 인스턴스의 메모리는 기본적으로 아주 적은량만 사용할 수 있다는 전제를 항상 고려해야합니다.
캐시 데이터가 담길 공간 뿐 아니라 실제 인스턴스가 커넥션을 관리하고 연산을 수행하기 위한 공간도 여유롭게 확보가 되어야하기 때문에 너무 많은 데이터가 담기게 되면 곤란해요. (캐시데이터가 아주 많아봐야 몇백메가 수준에서 끊겨야합니다.)

따라서 좌석상태 정보 같은것들은 무조건 EXTERNAL_CACHE_MANAGER를 사용하도록 하고,
콘서트 목록 정보 같은것들은 INTERNAL_CACHE_MANAGER와 EXTERNAL_CACHE_MANAGER를 둘 다 사용하는 것이 유리합니다.

INTERNAL_CACHE_MANAGER에 LFU 또는 LRU 정책(보통 LFU는 효율적으로 동작하도록 구현하기 까다로워서 LRU를 이용합니다.)을 설정해놓으면 기계적으로 자주 사용되는 데이터는 메모리도 갖고 있고, INTERNAL_CACHE_MANAGER가 가지고 있지 않은 데이터도 EXTERNAL_CACHE_MANAGER가 갖고 있기 때문에
인메모리를 먼저 탐색하고 없으면 Redis를 탐색하게 하는 식으로 구현할 수 있습니다.

또한 제시해주신 상황처럼 인메모리 캐시 매니저를 직접 구현하는것이 까다롭기 때문에 아예 로컬에 레디스를 하나 더 띄워서 인메모리 캐시처럼 사용하는 경우도 충분히 많이 사용되는 패턴인데요,
이 경우 예시로 붙여주신 코드처럼 그냥 단순히 연결하는 아이피만 스위칭 해주시면 됩니다. (적절하게 잘 설정하신 것 같다는 말씀을 드리는 겁니다 !)

잘 하고 계십니다. 그 방향 그대로 가면서 더 개선할 부분은 없을지 고민해가시면 될 것 같습니다.

---
🍎3. 레디스 분산락에서, 좌석 예약처럼 단 하나의 요청만 성공해야하는 경우
나머지 트랜잭션들은 재시도 없이 바로 throw Error하는 것이 나을까요? 
100개 요청 중 1번째만 성공한다면, 나머지 99개는 어차피 실패해야할 요청인데 lock을 대기할 필요 없는것처럼 느껴져서, 여쭤봅니다.

---
프로덕트 관점에서 생각을 해보겠습니다.

좌석을 선점 한 경우 해당 유저가 매우 짧은 시간 내에 선점한 좌석을 포기하거나 클라이언트 오류로 인해 다음 프로세스를 진행하지 못하는 경우 정도를 제외하고는 선점된 좌석을 다른 유저가 또 선점할 수 있는 경우는 없습니다. 또한 이렇게 될 가능성 자체도 매우 희박하구요.
따라서 유저들은 좌석 선점에 실패한 경우 이 좌석을 선점하기 위해 내부적으로 재시도 로직이 도는 것 보다, 얼른 좌석 선점에 실패했다는 문구가 나오면서 다른 좌석을 선점할 수 있도록 해주는 것을 더 원할겁니다.

따라서 이런 케이스에서는 의도적으로 재시도 로직을 넣지 않는것이 맞습니다.


ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ 다른사람 질문 ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
*
분산락을 이용하는 트랜잭션이라도 DB를 제어하는 로직이 들어가있으면 가능한 DB 락도 같이 이용하는게 일반적입니다. 이는 단순히 원자성 보장만을 위해서는 아니고, DB 트랜잭션에 실패하는 경우 롤백이 돌게 되는데 이를 수동으로 구현하는 것보다 그냥 DB에서 제공되는 롤백 기능을 사용하는게 더 안전하고 쉽기 때문입니다.
만약 하나의 분산락 트랜잭션 안에 2개의 DB 트랜잭션이 돌게된다면, 적절하게 Exception을 throw해주는 것만으로도 두개의 DB에 대한 롤백이 손쉽게 구현됩니다.

“분산락 ON -> DB 트랜잭션 수행 -> 분산락 OFF”은
분산락을 실수로 깜빡하기 쉬운듯..

* 로그 질문
실제 운영환경에서는 필수적인 로그만 쌓음. - 로그레벨
- 데이터독같은 APM을 사용하신다면 APM에서 제공하는 로깅 기능을 활용하면 효과적이구요, 이외에 ElasticSearch나 AWS의 CloudWatch 등의 클라우드 서비스에서 제공하는 로그 저장소를 사용하게됩니다.
- 그냥 S3같은데 쌓아놓으면 될것같지만, 로그는 저장하는것만큼 검색하는것도 중요하기 때문에 검색 기능이 잘 되어있는 저장공간에 쌓아두는것이 중요합니다.
- BUT 이런 외부 서비스도 저장가능한 용량의 제한이 분명히 존재하므로, 무한정 계속 쌓아둘 수는 없기에 일정 기간이 지난 로그는 압축해서 S3같은데 보관시켜놓는것이 좋습니다.
텍스트파일이기때문에 압축하면 용량이 엄청나게 줄어들게 되므로 용량 압박이 거의 해소됩니다.
그래서 보통 2주~한달 정도 지난 로그는 이런 아카이브에 넣어놓고 사고가 발생했거나하는 특별한 상황에서만 꺼내서 씁니다. 

-> 즉, 이 두 가지는 2주~한달 이내만 저장해두고 (내가 직접 관리하는 서버 or 돈내고 쓰는 서비스에. 검색이 잘 되는 비싼곳..)
1. warn/error 필수로그는 운영환경에(signoz, pm2,..)
2. 액세스로그는 데이터독 같은 APM에 (어쨌든 외부 서버)
3. 2주~한달 이상 지난 로그는 S3에 압축해서 쌓아놓고 필요할 때 본다.

